# OmniFlow工作流指南

OmniFlow是一个基于节点的编辑器，用于创建和执行本地LLM工作流。本文档将指导你如何设计、构建和执行有效的工作流。




## 工作流基础概念

工作流由**节点**和**连接**组成：
- **节点**：执行特定功能的组件，如文本输入、LLM查询等
- **连接**：定义节点之间数据流向的箭头

## 节点类型

### 1. 文本输入节点 (Text Input)
- **功能**：允许用户输入文本
- **输出**：用户输入的文本
- **应用场景**：作为工作流的起点，提供初始提示或查询

### 2. LLM查询节点 (LLM Query)
- **功能**：将输入发送到LLM（如GPT模型、Llama2等）处理
- **输入**：文本提示
- **输出**：LLM生成的回复
- **应用场景**：文本生成、问题回答、内容总结

### 3. 网络搜索节点 (Web Search)
- **功能**：基于输入执行网络搜索
- **输入**：搜索查询
- **输出**：搜索结果摘要
- **应用场景**：获取最新信息、补充LLM知识

### 4. 文档查询节点 (Document Query)
- **功能**：在指定文档中搜索相关内容
- **输入**：查询文本
- **配置**：文档路径
- **输出**：文档中的相关段落
- **应用场景**：从特定文档中检索信息

### 5. 模型选择器节点 (Model Selector)
- **功能**：选择要使用的LLM模型
- **输出**：所选模型名称
- **应用场景**：为LLM查询节点指定不同的模型

### 6. 自定义节点 (Custom Node)
- **功能**：执行用户定义的JavaScript代码
- **输入**：上游节点的输出
- **输出**：代码处理后的结果
- **应用场景**：自定义数据处理、格式转换

## 构建工作流示例

### 示例1：基础问答工作流

1. **文本输入** → **LLM查询**
   - 用户输入问题
   - LLM生成回答

### 示例2：网络增强的问答工作流

1. **文本输入** → **网络搜索**
2. **网络搜索** → **LLM查询**
3. **文本输入** → **LLM查询**
   - 用户输入问题
   - 系统执行网络搜索获取上下文
   - LLM基于问题和网络搜索结果生成回答

### 示例3：多源信息处理工作流

1. **文本输入** (问题) → **LLM查询**
2. **文档查询** → **LLM查询**
3. **网络搜索** → **LLM查询**
4. **LLM查询** → **自定义节点** (合并并格式化结果)
   - 系统从多个来源获取信息
   - LLM处理各类信息
   - 自定义节点整合输出

## 工作流执行过程

1. **初始化**：系统识别所有无输入连接的节点作为起点
2. **执行流程**：系统从起点开始，按照连接顺序执行每个节点
3. **数据传递**：每个节点的输出传递给连接的下游节点
4. **结果显示**：执行完成后，每个节点的处理结果显示在结果面板中

## 最佳实践

1. **简单开始**：从基础工作流开始，逐步添加复杂性
2. **输入连接**：确保每个需要输入的节点都有上游连接
3. **模型选择**：根据任务要求选择合适的LLM模型
4. **自定义处理**：利用自定义节点进行后处理和格式化
5. **分支工作流**：一个节点可以连接多个下游节点，形成分支处理
6. **合并输入**：一个节点可以接收多个上游节点的输入

## 调试工作流

1. **检查节点状态**：确保每个节点配置正确
2. **查看中间结果**：执行工作流后检查每个节点的输出
3. **调整连接**：修改节点连接以改变数据流向
4. **修改提示**：优化文本输入以获得更好的LLM响应

---

通过按照以上指南，你可以在OmniFlow中创建强大的本地LLM工作流，无需编程即可实现复杂的自动化任务。

